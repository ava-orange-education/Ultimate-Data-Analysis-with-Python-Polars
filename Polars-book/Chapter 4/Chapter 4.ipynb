{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b425e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Read the JSON file into a Polars DataFrame\n",
    "df = pl.read_json('trades.json')\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421abf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Read the NDJSON file into a Polars DataFrame\n",
    "df = pl.read_ndjson('tradesnd.json')\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c800f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# File path\n",
    "file_path = 'credit_card_transactions.parquet'\n",
    "\n",
    "# Read the Parquet file into a Polars DataFrame\n",
    "df = pl.read_parquet(file_path)\n",
    "\n",
    "# Get the file size\n",
    "file_size = os.path.getsize(file_path)\n",
    "\n",
    "# Print the DataFrame and file size\n",
    "print(df.head())\n",
    "print(\"row count is = \",df.height)\n",
    "print(f\"File size: {file_size / (1024 * 1024):.2f} MB\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# File path for the CSV file\n",
    "file_path = 'credit_card_transactions.csv'\n",
    "\n",
    "# Read the CSV file into a Polars DataFrame\n",
    "df = pl.read_csv(file_path, separator='|', skip_rows=4)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f871c-1268-4c15-8c11-549039b7468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_excel(\"Excel Pillar Data.xlsx\", sheet_name=\"Sheet1\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911101a-b4d6-4ea1-9109-fd8134aa945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to generate random traffic data\n",
    "def generate_traffic_data(rows):\n",
    "    vehicle_types = [\"Car\", \"Bus\", \"Motorbike\", \"Truck\", \"Auto\"]\n",
    "    road_conditions = [\"Clear\", \"Congested\", \"Accident\", \"Construction\", \"Heavy Rain\"]\n",
    "    \n",
    "    # Generate random data\n",
    "    data = {\n",
    "        \"Timestamp\": [datetime.now() - timedelta(minutes=random.randint(1, 1000)) for _ in range(rows)],\n",
    "        \"Traffic Volume\": [random.randint(50, 3000) for _ in range(rows)],  # Vehicles per hour\n",
    "        \"Road Condition\": [random.choice(road_conditions) for _ in range(rows)],\n",
    "        \"Speed Limit\": [random.choice([40, 50, 60, 70, 80]) for _ in range(rows)],  # km/h\n",
    "        \"Vehicle Type\": [random.choice(vehicle_types) for _ in range(rows)],\n",
    "    }\n",
    "    \n",
    "    return pl.DataFrame(data)\n",
    "\n",
    "# Create the DataFrame with 100 rows\n",
    "df = generate_traffic_data(100)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3880a-29ee-4267-b0ac-214ee2812a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_csv(\"bangalore_traffic_data.csv\")\n",
    "print(\"CSV file saved.\") # Export to JSON \n",
    "df.write_json(\"bangalore_traffic_data.json\") \n",
    "print(\"JSON file saved.\") # Export to NDJSON \n",
    "df.write_ndjson(\"bangalore_traffic_data.ndjson\")\n",
    "print(\"NDJSON file saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784d954-6292-4b1b-b06e-ab60545e5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_excel(\"bangalore_traffic_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed4297-32d8-46d7-8fff-8c6777377dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a sample DataFrame for electronic store sales data\n",
    "data = {\n",
    "    \"Transaction ID\": [f\"TXN{str(i).zfill(5)}\" for i in range(1, 11)],\n",
    "    \"Product\": [\"Laptop\", \"Phone\", \"Tablet\", \"Laptop\", \"Headphones\", \"Phone\", \"Tablet\", \"Laptop\", \"Phone\", \"Headphones\"],\n",
    "    \"Quantity\": [random.randint(1, 5) for _ in range(10)],\n",
    "    \"Price per Unit\": [random.randint(500, 1500) for _ in range(10)],\n",
    "    \"Date of Sale\": [datetime.now().strftime(\"%Y-%m-%d\") for _ in range(10)],\n",
    "    \"Store Location\": [\"Bangalore\", \"Chennai\", \"Mumbai\", \"Bangalore\", \"Delhi\", \"Chennai\", \"Mumbai\", \"Bangalore\", \"Delhi\", \"Chennai\"]\n",
    "}\n",
    "\n",
    "df = pl.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a2618-f56b-45b7-ba32-50ad0cd2cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a single column (Price per Unit)\n",
    "price_column = df[\"Price per Unit\"]\n",
    "print(\"Selected 'Price per Unit' column:\")\n",
    "print(price_column)\n",
    "\n",
    "# Selecting multiple columns (Product, Quantity, Price per Unit)\n",
    "selected_columns = df.select([\"Product\", \"Quantity\", \"Price per Unit\"])\n",
    "print(\"Selected multiple columns (Product, Quantity, Price per Unit):\")\n",
    "print(selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba94af5-0deb-4170-aa8c-2fde3f1beb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "df_renamed = df.rename({\"Transaction ID\": \"TransactionID\", \"Price per Unit\": \"Unit Price\"})\n",
    "print(\"DataFrame with renamed columns:\")\n",
    "print(df_renamed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd171e-bb7d-47f7-b051-51534ee9501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column for total sales (Quantity * Price per Unit)\n",
    "df_with_total = df.with_columns((df[\"Quantity\"] * df[\"Price per Unit\"]).alias(\"Total Sales\"))\n",
    "print(\"DataFrame with 'Total Sales' column:\")\n",
    "print(df_with_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b2309-52d8-440c-9117-8434b439712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering rows where the quantity sold is greater than 2\n",
    "filtered_df = df.filter(df[\"Quantity\"] > 2)\n",
    "print(\"Filtered DataFrame where Quantity > 2:\")\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900e160-3cc6-47e7-b06d-2999ae16157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by 'Quantity' in ascending order\n",
    "sorted_df_desc = df.sort(\"Quantity\")\n",
    "print(\"DataFrame sorted by 'Quantity' in descending order:\")\n",
    "print(sorted_df_desc)\n",
    "\n",
    "# Sorting by 'Product' and 'Quantity' (first by product, then by quantity)\n",
    "sorted_df_multiple = df.sort([\"Product\", \"Quantity\"])\n",
    "print(\"DataFrame sorted by 'Product' and 'Quantity':\")\n",
    "print(sorted_df_multiple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecad918-cae7-4a3a-a542-deefc8a5b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column for Total Sales (Quantity * Price per Unit)\n",
    "df_with_total_sales = df.with_columns((df[\"Quantity\"] * df[\"Price per Unit\"]).alias(\"Total Sales\"))\n",
    "print(df_with_total_sales)\n",
    "\n",
    "# Adding a column that categorizes products into 'High Value' or 'Low Value' based on a threshold\n",
    "df_with_value_category = df_with_total_sales.with_columns(\n",
    "    (pl.col(\"Total Sales\") > 3000).alias(\"High Value\")\n",
    ")\n",
    "print(df_with_value_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99822cce-3e56-4194-b1f9-d245bb1fdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical columns\n",
    "summary = df.describe()\n",
    "print(summary)\n",
    "\n",
    "# Group-wise aggregation: Calculate the total sales per product\n",
    "grouped = df_with_value_category.group_by(\"Product\").agg(\n",
    "    [\n",
    "        pl.col(\"Total Sales\").sum().alias(\"Total Sales Per Product\"),\n",
    "        pl.col(\"Quantity\").sum().alias(\"Total Quantity Sold\"),\n",
    "        pl.col(\"Price per Unit\").mean().alias(\"Average Price per Unit\")\n",
    "    ]\n",
    ")\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81b70d-75fe-4628-9768-562f2b0bbfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_row = pl.DataFrame({\n",
    "    \"Transaction ID\": [None],\n",
    "    \"Product\": [None],\n",
    "    \"Quantity\": [None],\n",
    "    \"Price per Unit\": [None],\n",
    "    \"Date of Sale\": [None],\n",
    "    \"Store Location\": [None]\n",
    "})\n",
    "\n",
    "# Append the null row to the existing dataframe\n",
    "df = df.vstack(null_row)\n",
    "print(\"dataframe with null\")\n",
    "print(df)\n",
    "\n",
    "# Identifying missing data: Check for missing values in the 'Quantity' column\n",
    "missing_quantity = df.filter(pl.col(\"Quantity\").is_null())\n",
    "print(missing_quantity)\n",
    "\n",
    "# Handling missing values: Replace missing values with a default value (e.g., fill with 0 for 'Quantity' and 1000 for 'Price per Unit')\n",
    "df_filled = df.fill_null(0)\n",
    "print(df_filled)\n",
    "\n",
    "# Drop rows with missing values (optional)\n",
    "df_dropped = df.drop_nulls()\n",
    "print(df_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd879f7-2704-4690-9f98-3b311b9fb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows based on all columns\n",
    "df_no_duplicates = df.unique()\n",
    "print(\"unique rows with one column for selection\")\n",
    "print(df_no_duplicates)\n",
    "\n",
    "# Remove duplicate rows based on specific columns (e.g., 'Product' and 'Store Location')\n",
    "df_no_duplicates_specific = df.unique(subset=[\"Product\", \"Store Location\"])\n",
    "print(\"unique rows with two columns for selection\")\n",
    "print(df_no_duplicates_specific)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d5e55-3a5d-4a2c-aa6e-7e7651b96739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names: Convert to lower case and replace spaces with underscores\n",
    "df_standardized_columns = df.rename({col: col.lower().replace(\" \", \"_\") for col in df.columns})\n",
    "print(df_standardized_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2654f5d-7632-47f3-a637-8addfa697104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean strings: Convert to lowercase, trim leading/trailing whitespace, and remove any extra spaces between words\n",
    "df_cleaned_strings = df.with_columns([\n",
    "    pl.col(\"Product\")\n",
    "    .str.strip_chars()  # Trim whitespace\n",
    "    .str.to_lowercase()  # Convert to lowercase\n",
    "    .str.replace_all(r\"\\s+\", \" \")  # Replace multiple spaces with a single space\n",
    "    .alias(\"Cleaned Product\")\n",
    "])\n",
    "print(\"cleaned column\")\n",
    "print(df_cleaned_strings)\n",
    "\n",
    "# Explode a string column into a list of words (split by spaces)\n",
    "df_exploded = df.with_columns([\n",
    "    pl.col(\"Product\").str.split(\" \").alias(\"Exploded Product\")\n",
    "])\n",
    "print(\"exploded column\")\n",
    "print(df_exploded)\n",
    "\n",
    "# Extract a substring using regular expressions (e.g., extract the first char)\n",
    "df_regex_extracted = df.with_columns([\n",
    "    pl.col(\"Product\").str.extract(r\"(\\w)\", 1).alias(\"First Word\")\n",
    "])\n",
    "print(\"Regex Extraction\")\n",
    "print(df_regex_extracted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876819c0-ddee-46ba-803d-abfa4283ba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c664bb3e-3c00-40a8-a899-7ca826081e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d78c6-c748-4615-837e-3774fbb67fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
